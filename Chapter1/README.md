## 머신러닝이란?
- 머신러닝은 데이터로부터 학습하도록 컴퓨터를 프로그래밍 하는 것
- 일반적인 정의는, 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야이다.
#
### 데이터 마이닝
- 머신러닝 기술을 적용해서 대용량의 데이터를 분석하면 겉으로는 보이지 않던 패턴을 발견할 수 있다.
- 가끔 예상치 못한 연관 관계나 새로운 추세가 발견되기도 해서 해당 문제를 더 잘 이해하도록 도와준다.
#
### 머신러닝의 이용했을 때, 뛰어난 분야?
- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제
    - 하나의 머신러닝 모델이 코드를 간단하게 만들고 전통적인 방법보다 더 잘 수행되도록 할 수 있다.
- 전통적인 방식으로는 해결 방법이 없는 복잡한 문제
    - 가장 뛰어난 머신러닝 기법으로 해결 방법을 찾을 수 있다.
- 유동적인 환경
    - 머신러닝 시스템은 새로운 데이터에 적응할 수 있다.
- 복잡한 문제와 대량의 데이터에서 통찰 얻기

#
### 머신러닝 시스템의 종류
- 지도, 비지도, 준지도, 강화 학습
    - 사람의 감독하에 훈련하는 것인지 그렇지 않은 것인지
- 온라인 학습, 배치 학습
    - 실시간으로 점진적인 학습을 하는지 아닌지
- 사례 기반 학습과 모델 기반 학습
    - 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지 아니면 과학자들이 하는 것처럼 훈련 데이터셋에서 패턴을 발견하여 예측 모델을 만드는지

#
### 지도 학습과 비지도 하습
- 지도 학습 (supervised learning)
    - 알고리즘에 주입하는 훈련 데이터에 레이블(label)이라는 원하는 답이 포함된다.
    - 분류(classification)가 전형적인 지도 학습, 스팸 필터가 좋은 예이다.
    - 회귀(regression)는 예측 변수(predictor variable)라 부르는 특성(feature)을 사용해 중고차 가격 같은 타깃(target) 수치를 예측하는 것이다.
    - 지도 학습 알고리즘
        - k-최근접 이웃 (k-nearest neighbors)
        - 선형 회귀 (linear regression)
        - 로지스틱 회귀 (logistic regression)
        - 서포트 벡터 머신 (support vector machine, SVM)
        - 결정 트리 (decision tree)와 랜덤 포레스트 (random forest)
        - 신경망 (neural networks)

- 비지도 학습 (unsupervised learning)
    - 훈련 데이터에 레이블이 없다.
    - 시스템이 아무런 도움 없이 학습해야 한다.
    - 비지도 학습 알고리즘
        - 군집 (clustering)
            - k-평균 (k-means)
            - DBSCAN
            - 계층 군집 분석 (hierarchical cluster analysis, HCA)
        - 이상치 탐지 (outlier detection)와 특이치 탐지 (novelty detection)
            - 원-클래스 (one-class SVM)
            - 아이솔레이션 포레스트 (isolation forest)
        - 시각화 (visualization)와 차원 축소 (dimensionality reduction)
            - 주성분 분석 (principal component analysis, PCA)
            - 커널 (kernel) PCA
            - 지역적 선형 임베딩 (locally-linear embedding, LLE)
        - 연관 규칙 학습 (association rule learning)
- 준지도 학습
    - 어떤 알고리즘은 일부만 레이블이 있는 데이터를 다룰 수 있다.
    - 지도 학습과 비지도 학습의 조합으로 이루어져 있다.
- 강화 학습
    - 학습하는 시스템을 에이전트라고 부르며, 환경을 관찰해서 행동을 실행하고 그 결과로 보상(또는 벌점)을 받는다.

            

#
### 차원 축소 (demensionality reduction)
- 너무 많은 정보를 잃지 않으면서 데이터를 간소화
- 이렇게 하는 한 가지 방법은 특성 추출(feature extraction)을 한다.
    - 상관관계가 있는 여러 특성을 하나로 합치는 것
    - 예를 들어 차의 주행거리는 연식과 강하게 연관되어 있으므로 차원 축소 알고리즘으로 두 특성을 차의 마모 정도를 나타내는 하나의 특성으로 합칠 수 있다.

#

### 1.4.2 배치 학습과 온라인 학습
### 배치 학습 (batch learning)
- 시스템이 점진적으로 학습할 수 없다. 가용한 데이터를 모두 사용해 훈련한다,
- 오프라인 학습(offline learning)
- 간단하고 잘 작동하지만, 전체 데이터셋을 사용해 훈련하는 데 몇 시간이 소요될 수 있다.

### 온라인 학습 (online learning)
- 데이터를 순차적으로 한 개씩 또는 미니배치(mini-batch)라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킨다.
- 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습할 수 있다.

#
### 1.4.3 사례 기반 학습과 모델 기반 학습
### 사례 기반 학습
- 유사도 측정을 사용해 새로운 데이터와 학습한 샘플을 비교하는 식으로 일반화한다
### 모델 기반 학습
- 샘플들의 모델을 만들어 예측(prediction)에 사용하는 것
#

### 과대적합 (overfitting)
- 모델이 훈련 데이터에 너무 잘 맞지만, 일반성이 떨어진다는 뜻
- 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 발생한다.
- 규제는 과대적합의 위험을 감소시킨다.

### 과대적합의 해결 방법?
- 파라미터 수가 적은 모델을 선택하거나(예를 들면 고차원 다항 모델보다 선형 모델), 훈련 데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가하여 단순화시킨다.
- 훈련 데이터를 더 많이 모은다.
- 훈련 데이터의 잡음을 줄인다. (예를 들면 오류 데이터 수정과 이상치 제거)
#
### 과소적합 (underfitting)
- 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 발생

### 과소적합 해결 방법?
- 모델 파라미터가 더 많은 강력한 모델을 선택
- 학습 알고리즘에 더 많은 특성을 제공
- 모델의 제약을 줄인다. (예를 들면 규제 하이퍼파라미터를 감소시킨다.)

---

<details>
<summary>1. 머신러닝을 어떻게 정의할 수 있나요?</summary>
<div markdown="1">       
데이터로부터 학습할 수 있는 시스템을 만드는 것이다. 학습이란 어떤 작업에서 주어진 성능 지표가 더 나아지는 것을 의미한다.
</div>
</details>

<details>
<summary>2. 머신러닝이 도움을 줄 수 있는 문제 유형 네 가지를 말해보세요.</summary>
<div markdown="2">
1) 명확한 해결책이 없는 복잡한 문제 <br />
2) 수작업으로 만든 긴 규칙 리스트를 대체하는 경우 <br />
3) 변화하는 환경에 적응하는 시스템을 만드는 경우 <br />
4) 사람에게 통찰을 제공해야 하는 경우(예를 들면 데이터 마이닝)
</div>
</details>

<details>
<summary>3. 레이블된 훈련 세트란 무엇인가요?</summary>
<div markdown="3">
각 샘플에 대해 원하는 정답(레이블)을 담고 있는 훈련 세트이다.
</div>
</details>

<details>
<summary>4. 가장 널리 사용되는 지도 학습 작업 두 가지는 무엇인가요?</summary>
<div markdown="4">
회귀와 분류
</div>
</details>

<details>
<summary>5. 보편적인 비지도 학습 네 가지는 무엇인가요?</summary>
<div markdown="5">
군집, 시각화, 차원 축소, 연관 규칙 학습
</div>
</details>

<details>
<summary>6. 사전 정보가 없는 여러 지형에서 로봇을 걸어가게 하려면 어떤 종류의 머신러닝 알고리즘을 사용할 수 있나요?</summary>
<div markdown="6">
강화 학습
</div>
</details>

<details>
<summary>7. 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 하나요?</summary>
<div markdown="7">
만약 그룹을 어떻게 정의할지 모른다면 비슷한 고객끼리 군집으로 나누기 위해 군집 알고리즘(비지도 학습)을 사용할 수 있습니다. 그러나 어떤 그룹이 있어야 할지 안다면 분류 알고리즘(지도 학습)에 각 그룹에 대한 샘플을 주입합니다. 그러면 알고리즘이 전체 고객을 여러 그룹으로 분류하게 될 것입니다.
</div>
</details>

<details>
<summary>8. 스팸 감지의 문제는 지도 학습과 비지도 학습 중 어떤 문제로 볼 수 있나요?</summary>
<div markdown="8">
스팸 감지는 전형적인 지도 학습 문제입니다. 알고리즘에 많은 이메일과 이에 상응하는 레이블(스팸 혹은 스팸 아님)이 제공됩니다.
</div>
</details>

<details>
<summary>9. 온라인 학습 시스템이 무엇인가요?</summary>
<div markdown="9">
배치 학습 시스템과 달리 점진적으로 학습할 수 있습니다. 이 방식은 변화하는 데이터와 자율 시스템에 빠르게 적응하고 매우 많은 양의 데이터를 훈련시킬 수 있습니다.
</div>
</details>

<details>
<summary>10. 외부 메모리 학습이 무엇인가요?</summary>
<div markdown="10">
외부 메모리 알고리즘은 컴퓨터의 주메모리에 들어갈 수 없는 대용량의 데이터를 다룰 수 있습니다. 외부 메모리 학습 알고리즘은 데이터를 미니배치로 나누고 온라인 학습 기법을 사용해 학습합니다.
</div>
</details>

<details>
<summary>11. 예측을 하기 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇인가요?</summary>
<div markdown="11">
사례 기반 학습 알고리즘은 훈련 데이터를 기억하는 학습입니다. 새로운 샘플이 주어지면 유사도 측정을 사용해 학습된 샘플 중에서 가장 비슷한 것을 찾아 예측으로 사용합니다.
</div>
</details>

<details>
<summary>12. 모델 파라미터와 학습 알고리즘의 하이퍼파라미터 사이에는 어떤 차이가 있나요?</summary>
<div markdown="12">
모델은 하나 이상의 파라미터(예를 들면 선형 모델의 기울기)를 사용해 새로운 샘플이 주어지면 무엇을 예측할지 결정합니다. 학습 알고리즘은 모델이 새로운 샘플에 잘 일반화되도록 이런 파라미터들의 최적값을 찾습니다. 하이퍼파라미터는 모델이 아니라 이런 학습 알고리즘 자체의 파라미터입니다. (예를 들면 적용할 규제의 정도)
</div>
</details>

<details>
<summary>13. 모델 기반 알고리즘이 찾는 것은 무엇인가요? 성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은 무엇인가요? 예측은 어떻게 만드나요?</summary>
<div markdown="13">
모델 기반 학습 알고리즘은 새로운 샘플에 잘 일반화되기 위한 모델 파라미터의 최적값을 찾습니다. 일반적으로 훈련 데이터에서 시스템의 예측이 얼마나 나쁜지 측정하고 모델에 규제가 있다면 모델 복잡도에 대한 페널티를 더한 비용 함수를 최소화함으로써 시스템을 훈련시킵니다. 예측을 만들려면 학습 알고리즘이 찾은 파라미터를 사용하는 모델의 예측 함수에 새로운 샘플의 특성을 주입합니다.
</div>
</details>

<details>
<summary>14. 머신러닝의 주요 도전 과제는 무엇인가요?</summary>
<div markdown="14">
부족한 데이터, 낮은 데이터 품질, 대표성 없는 데이터, 무의미한 특성, 훈련 데이터에 과소적합된 과도하게 간단한 모델, 훈련 데이터에 과대적합된 과도하게 복잡한 모델 등입니다.
</div>
</details>

<details>
<summary>15. 모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 건가요? 가능한 해결책 세 가지는 무엇인가요?</summary>
<div markdown="15">
훈련 데이터에 과대적합되었을 가능성이 높다.
해결책
- 더 많은 데이터를 모은다.
- 모델을 단순화한다. (간단한 알고리즘을 선택 / 특성이나 파라미터의 수를 줄인다 / 모델에 규제를 추가)
- 훈련 데이터에 있는 잡음을 감소시킨다.
</div>
</details>

<details>
<summary>16. 테스트 세트가 무엇이고 왜 사용해야 하나요?</summary>
<div markdown="16">
테스트 세트는 실전에 배치되기 전에 모델이 새로운 샘플에 대해 만들 일반화 오차를 추정하기 위해 사용합니다.
</div>
</details>

<details>
<summary>17. 검증 세트의 목적은 무엇인가요?</summary>
<div markdown="17">
검증 세트는 모델을 비교하는 데 사용됩니다. 이를 사용해 가장 좋은 모델을 고르고 하이퍼파라미터를 튜닝합니다.
</div>
</details>

<details>
<summary>19. 테스트 세트를 사용해 하이퍼파라미터를 튜닝하면 어떤 문제가 생기나요?</summary>
<div markdown="19">
테스트 세트를 사용해 하이퍼파라미터를 튜닝하면 테스트 세트에 과대적합될 위험이 있고 일반화 오차를 낙관적으로 측정하게 됩니다. (모델을 출시하면 기대한 것보다 나쁜 성능을 낼 것입니다.)
</div>
</details>
